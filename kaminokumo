#!/usr/bin/python3

import argparse
import json
import code
import readline
import signal
import sys
import os
import requests
import urllib3
from time import sleep
from bs4 import BeautifulSoup
import subprocess
import re


def SigHandler_SIGINT(signum, frame):
    print()
    sys.exit(0)


class Argparser(object):
    def __init__(self):
        parser = argparse.ArgumentParser()
        parser.add_argument("--url", type=str, nargs="+", help="url to scrape")
        parser.add_argument("--name", type=str, nargs="+",
                            help="url to scrape")
        parser.add_argument("--dbg", action="store_true",
                            help="debug", default=False)
        parser.add_argument("--demon", action="store_true",
                            help="run as daemon", default=False)
        parser.add_argument("--manga", action="store_true",
                            help="run manga scraper", default=False)
        parser.add_argument("--cb", action="store_true",
                            help="run cb scraper", default=False)
        parser.add_argument("--slumber", type=int,
                            help="how long the demon sleeps", default=60)
        self.args = parser.parse_args()


def mrg(url):
    requests.packages.urllib3.disable_warnings()
    resp = requests.get(url, verify=False)
    soup = BeautifulSoup(resp.text, "lxml")
    search = soup.find_all("div", class_="label")

    Up_Time = str()
    for elem in search:
        if elem.string == "Last Broadcast:":
            Up_Time = elem.next_sibling.next_sibling.string
            # print(elem.next_sibling.next_sibling)

    if Up_Time.find("minutes") != -1:
        return True
    else:
        return False


def run_cb_scrape():
    url = json.load(open("/home/bloodstalker/extra/kaminokumo/data.json"))
    if mrg(url["1"]):
        print("mg ", end="")
        vocalize(os.path.expanduser("~") + "/scripts/mila/mgup.ogg")
    if mrg(url["2"]):
        print("obk ", end="")
        vocalize(os.path.expanduser("~") + "/scripts/mila/obkup.ogg")
    if mrg(url["5"]):
        print("ls ", end="")
        vocalize(os.path.expanduser("~") + "/scripts/mila/lisaup.ogg")


def manga_scrape():
    urls = json.load(open("/home/bloodstalker/extra/kaminokumo/manga.json"))
    requests.packages.urllib3.disable_warnings()
    result = str()
    for name, url in urls.items():
        resp = requests.get(url, verify=False)
        soup = BeautifulSoup(resp.text, "lxml")
        search = soup.find_all("a", class_="chapter-name text-nowrap")
        re_res = []
        for thing in search:
            re_res.append(re.findall("Chapter [0-9]*[\.[0-9]*]?", thing.text))
        # print(name, "-->", re_res[0][0])
        result += name + "-->" + re_res[0][0] + "\n"
    print(result, end="")


def vocalize(sound):
    subprocess.call([os.path.expanduser("~")+"/scripts/voice.sh", sound])
###############################################################################


def premain(argparser):
    signal.signal(signal.SIGINT, SigHandler_SIGINT)
    if argparser.args.cb:
        run_cb_scrape()
    elif argparser.args.manga:
        manga_scrape()
    else:
        pass


def main():
    argparser = Argparser()
    if argparser.args.dbg:
        try:
            premain(argparser)
        except Exception as e:
            print(e.__doc__)
            if e.message:
                print(e.message)
            variables = globals().copy()
            variables.update(locals())
            shell = code.InteractiveConsole(variables)
            shell.interact(banner="DEBUG REPL")
    else:
        premain(argparser)


if __name__ == "__main__":
    main()
